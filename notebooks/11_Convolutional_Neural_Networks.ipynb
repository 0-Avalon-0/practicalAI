{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11_Convolutional_Neural_Networks",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "bOChJSNXtC9g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks (CNN)"
      ]
    },
    {
      "metadata": {
        "id": "OLIxEDq6VhvZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/logo.png\" width=150>\n",
        "\n",
        "In this lesson we will learn the basics of CNNs applied to image and text based data sources.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "VoMq0eFRvugb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Overview"
      ]
    },
    {
      "metadata": {
        "id": "ziGJNhiQeiGN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/cnn.png\" width=700>"
      ]
    },
    {
      "metadata": {
        "id": "qWro5T5qTJJL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* **Objective:**  Detect spatial substructure from input data to aid in classification, segmentation, etc.\n",
        "* **Advantages:** \n",
        "  * Small number of weights (shared)\n",
        "  * Parallelizable\n",
        "  * Detects spatial substrcutures (feature extractors)\n",
        "  * Interpretable via filters\n",
        "  * Used for in images/text/time-series etc.\n",
        "* **Disadvantages:**\n",
        "  * Many hyperparameters (kernel size, strides, etc.)\n",
        "  * Inputs have to be of same width (image dimensions, text length, etc.)\n",
        "* **Miscellaneous:** \n",
        "  * Lot's of deep CNN architectures constantly updated for SOTA performance"
      ]
    },
    {
      "metadata": {
        "id": "8nCsZGyWhI9f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Filters"
      ]
    },
    {
      "metadata": {
        "id": "lxpgRzIjiVHv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "At the core of CNNs are filters (weights, kernels, etc.) which convolve (slide) across our input to extract relevante features. The filters are initialized randomly but learn to pick up meaningful features from the input that aid in optimizing for the objective. We're going to teach CNNs in an unorthodox method where we entirely focus on applying it to 2D text data. Each input is composed of words and we will be representing each word as on-hot encoded vector which gives us our 2D input.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/conv.gif\" width=400>"
      ]
    },
    {
      "metadata": {
        "id": "1kTABJyYj91S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loading PyTorch library\n",
        "!pip3 install http://download.pytorch.org/whl/cpu/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kz9D2rrdmSl9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CFEbPKZFmSoZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d27259f9-1a41-4e74-e2d6-2e7143b46fb0"
      },
      "cell_type": "code",
      "source": [
        "# Assume all our inputs have the same # of words\n",
        "batch_size = 128\n",
        "sequence_size = 10 # words per input\n",
        "one_hot_size = 20 # vocab size\n",
        "x = torch.randn(batch_size, one_hot_size, sequence_size)\n",
        "print(\"Size: {}\".format(x.shape))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([128, 20, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8V4y9D75mSrA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e991b9b4-8a0b-46dc-a437-bf0d2677d214"
      },
      "cell_type": "code",
      "source": [
        "# Create filters for a conv layer\n",
        "out_channels = 96 # of filters\n",
        "kernel_size = 3 # filters are 3X3\n",
        "conv1 = nn.Conv1d(in_channels=one_hot_size, out_channels=out_channels, kernel_size=kernel_size)\n",
        "print(\"Size: {}\".format(conv1.weight.shape))\n",
        "print(\"Filter size: {}\".format(conv1.out_channels))\n",
        "print(\"Filter size: {}\".format(conv1.kernel_size[0]))\n",
        "print(\"Padding: {}\".format(conv1.padding[0]))\n",
        "print(\"Stride: {}\".format(conv1.stride[0]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([96, 20, 3])\n",
            "Filter size: 96\n",
            "Filter size: 3\n",
            "Padding: 0\n",
            "Stride: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x40mC6Q3mStp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5328ccda-01e1-4469-c4f4-e4f9a9d218c4"
      },
      "cell_type": "code",
      "source": [
        "# Convolve using filters\n",
        "conv_output = conv1(x)\n",
        "print(\"Size: {}\".format(conv_output.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([128, 96, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WE9ntwKOsZky",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We get 128 for the batch size, 96 outputs because that's how many filters we used on the input, but where is the 8 coming from? You can visually apply the convolution or use this handy equation:\n",
        "\n",
        "$\\frac{W - F + 2P}{S} + 1 = \\frac{10 - 3 + 2(0)}{1} + 1 = 8$\n",
        "\n",
        "where:\n",
        "  * W: width of each input\n",
        "  * F: filter size\n",
        "  * P: padding\n",
        "  * S: stride"
      ]
    },
    {
      "metadata": {
        "id": "vwTtF7bBuZvF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pooling"
      ]
    },
    {
      "metadata": {
        "id": "VXBbKPs1ua9G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The result of convolving filters on an input is a feature map. Due to the nature of convolution and overlaps, our feature map will have lots of redundant information. Pooling is a way to summarize a high-dimensional feature map into a lower dimensional one for simplified downstream computation. The pooling operation can be the max value, average, etc. in a certain receptive field.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/pool.jpeg\" width=450>"
      ]
    },
    {
      "metadata": {
        "id": "VCag6lk2mSwU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc2aa3b9-e305-4739-f5bd-35fdfc090c2e"
      },
      "cell_type": "code",
      "source": [
        "# Max pooling\n",
        "kernel_size = 2\n",
        "pool1 = nn.MaxPool1d(kernel_size=kernel_size, stride=2, padding=0)\n",
        "pool_output = pool1(conv_output)\n",
        "print(\"Size: {}\".format(pool_output.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([128, 96, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c_e4QRFwvTt8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$\\frac{W-F}{S} + 1 = \\frac{8-2}{2} + 1 = 4$"
      ]
    },
    {
      "metadata": {
        "id": "l9rL1EWIfi-y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNNs on text"
      ]
    },
    {
      "metadata": {
        "id": "aWtHDOJgHZvk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We're going use convolutional neural networks on text data, which involves 1D conv (nn.Conv1d) operations or 2D conv operations (if working with sentences). You can easily use this set up for time series data or extend it to 2D conv operations (nn.Conv1d) for image data, or nn.Conv3d for video processing. For text data, we will create filters of varying kernel sizes (2, 3, 4) which act as feature selectors of varying n-gram sizes. The outputs are concated and fed into a fully-connected layer for class predictions. \n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/cnn_text.jpg\" width=650>"
      ]
    },
    {
      "metadata": {
        "id": "bVBZxbaAtS9u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ]
    },
    {
      "metadata": {
        "id": "y8QSdEcDtXUs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "import collections\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VADCXjMwtXYN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set Numpy and PyTorch seeds\n",
        "def set_seeds(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        \n",
        "# Creating directories\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mpiCYECstXbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f88d7465-c36c-4590-de59-0b9075d5e35d"
      },
      "cell_type": "code",
      "source": [
        "# Arguments\n",
        "args = Namespace(\n",
        "    seed=1234,\n",
        "    cuda=False,\n",
        "    shuffle=True,\n",
        "    data_file=\"names.csv\",\n",
        "    split_data_file=\"split_names.csv\",\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"names\",\n",
        "    reload_from_files=False,\n",
        "    train_size=0.7,\n",
        "    val_size=0.15,\n",
        "    test_size=0.15,\n",
        "    num_epochs=20,\n",
        "    early_stopping_criteria=5,\n",
        "    learning_rate=1e-3,\n",
        "    batch_size=64,\n",
        "    num_filters=100,\n",
        ")\n",
        "\n",
        "# Set seeds\n",
        "set_seeds(seed=args.seed, cuda=args.cuda)\n",
        "\n",
        "# Create save dir\n",
        "handle_dirs(args.save_dir)\n",
        "\n",
        "# Expand filepaths\n",
        "args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\n",
        "args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
        "print(\"Expanded filepaths: \")\n",
        "print(\"\\t{}\".format(args.vectorizer_file))\n",
        "print(\"\\t{}\".format(args.model_state_file))\n",
        "\n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "print(\"Using CUDA: {}\".format(args.cuda))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\tnames/vectorizer.json\n",
            "\tnames/model.pth\n",
            "Using CUDA: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ptb4hJ4Bw8YU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data"
      ]
    },
    {
      "metadata": {
        "id": "bNxZQUqfmS0B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MBdQpUTQtMgu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Upload data from GitHub to notebook's local drive\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/data/surnames.csv\"\n",
        "response = urllib.request.urlopen(url)\n",
        "html = response.read()\n",
        "with open(args.data_file, 'wb') as fp:\n",
        "    fp.write(html)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6PYCeGrStMj7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4b73dcdc-a443-4122-e18c-49cbcdc4f1f2"
      },
      "cell_type": "code",
      "source": [
        "# Raw data\n",
        "df = pd.read_csv(args.data_file, header=0)\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>surname</th>\n",
              "      <th>nationality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Woodford</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Coté</td>\n",
              "      <td>French</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kore</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Koury</td>\n",
              "      <td>Arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lebzak</td>\n",
              "      <td>Russian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    surname nationality\n",
              "0  Woodford     English\n",
              "1      Coté      French\n",
              "2      Kore     English\n",
              "3     Koury      Arabic\n",
              "4    Lebzak     Russian"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "pbfVM-YatMnD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "afdb6a95-e15c-489e-f9bc-a91fa3c67481"
      },
      "cell_type": "code",
      "source": [
        "# Split by nationality\n",
        "by_nationality = collections.defaultdict(list)\n",
        "for _, row in df.iterrows():\n",
        "    by_nationality[row.nationality].append(row.to_dict())\n",
        "for nationality in by_nationality:\n",
        "    print (\"{0}: {1}\".format(nationality, len(by_nationality[nationality])))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English: 2972\n",
            "French: 229\n",
            "Arabic: 1603\n",
            "Russian: 2373\n",
            "Japanese: 775\n",
            "Chinese: 220\n",
            "Italian: 600\n",
            "Czech: 414\n",
            "Irish: 183\n",
            "German: 576\n",
            "Greek: 156\n",
            "Spanish: 258\n",
            "Polish: 120\n",
            "Dutch: 236\n",
            "Vietnamese: 58\n",
            "Korean: 77\n",
            "Portuguese: 55\n",
            "Scottish: 75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KdGOoKFjtMpz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create split data\n",
        "final_list = []\n",
        "for _, item_list in sorted(by_nationality.items()):\n",
        "    if args.shuffle:\n",
        "        np.random.shuffle(item_list)\n",
        "    n = len(item_list)\n",
        "    n_train = int(args.train_size*n)\n",
        "    n_val = int(args.val_size*n)\n",
        "    n_test = int(args.test_size*n)\n",
        "\n",
        "  # Give data point a split attribute\n",
        "    for item in item_list[:n_train]:\n",
        "        item['split'] = 'train'\n",
        "    for item in item_list[n_train:n_train+n_val]:\n",
        "        item['split'] = 'val'\n",
        "    for item in item_list[n_train+n_val:]:\n",
        "        item['split'] = 'test'  \n",
        "\n",
        "    # Add to final list\n",
        "    final_list.extend(item_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DyDwlzzKtMsz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a1f89c39-1930-4293-c1d8-83c98230e9ab"
      },
      "cell_type": "code",
      "source": [
        "# df with split datasets\n",
        "split_df = pd.DataFrame(final_list)\n",
        "split_df[\"split\"].value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "train    7680\n",
              "test     1660\n",
              "val      1640\n",
              "Name: split, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "17aHMQOwtMvh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
        "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
        "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
        "    return text\n",
        "    \n",
        "split_df.surname = split_df.surname.apply(preprocess_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wh6D8qfQmS2c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "108a3efc-00cf-4c48-8147-6ef515cc6ae2"
      },
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "split_df.to_csv(args.split_data_file, index=False)\n",
        "split_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nationality</th>\n",
              "      <th>split</th>\n",
              "      <th>surname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Arabic</td>\n",
              "      <td>train</td>\n",
              "      <td>bishara</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Arabic</td>\n",
              "      <td>train</td>\n",
              "      <td>nahas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Arabic</td>\n",
              "      <td>train</td>\n",
              "      <td>ghanem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Arabic</td>\n",
              "      <td>train</td>\n",
              "      <td>tannous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Arabic</td>\n",
              "      <td>train</td>\n",
              "      <td>mikhail</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  nationality  split  surname\n",
              "0      Arabic  train  bishara\n",
              "1      Arabic  train    nahas\n",
              "2      Arabic  train   ghanem\n",
              "3      Arabic  train  tannous\n",
              "4      Arabic  train  mikhail"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "6nZBgfQTuAA8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Vocabulary"
      ]
    },
    {
      "metadata": {
        "id": "TeRVQlRZuBgA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Vocabulary(object):\n",
        "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
        "\n",
        "        # Token to index\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self.token_to_idx = token_to_idx\n",
        "\n",
        "        # Index to token\n",
        "        self.idx_to_token = {idx: token \\\n",
        "                             for token, idx in self.token_to_idx.items()}\n",
        "        \n",
        "        # Add unknown token\n",
        "        self.add_unk = add_unk\n",
        "        self.unk_token = unk_token\n",
        "        if self.add_unk:\n",
        "            self.unk_index = self.add_token(self.unk_token)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'token_to_idx': self.token_to_idx,\n",
        "                'add_unk': self.add_unk, 'unk_token': self.unk_token}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        if token in self.token_to_idx:\n",
        "            index = self.token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self.token_to_idx)\n",
        "            self.token_to_idx[token] = index\n",
        "            self.idx_to_token[index] = token\n",
        "        return index\n",
        "\n",
        "    def add_tokens(self, tokens):\n",
        "        return [self.add_token[token] for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        if self.add_unk:\n",
        "            index = self.token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            index =  self.token_to_idx[token]\n",
        "        return index\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        if index not in self.idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self.idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bH8LMH9wuBi9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ac7d993f-24b9-4f8d-a7ad-954b8d08a83e"
      },
      "cell_type": "code",
      "source": [
        "# Vocabulary instance\n",
        "nationality_vocab = Vocabulary(add_unk=False)\n",
        "for index, row in df.iterrows():\n",
        "    nationality_vocab.add_token(row.nationality)\n",
        "print (nationality_vocab) # __str__\n",
        "print (nationality_vocab.lookup_token(\"English\"))\n",
        "print (nationality_vocab.lookup_index(0))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Vocabulary(size=18)>\n",
            "0\n",
            "English\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "57a1lzHPuHHm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Vectorizer"
      ]
    },
    {
      "metadata": {
        "id": "MwS5BEV-uBlt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SurnameVectorizer(object):\n",
        "    def __init__(self, surname_vocab, nationality_vocab, max_surname_length):\n",
        "        self.surname_vocab = surname_vocab\n",
        "        self.nationality_vocab = nationality_vocab\n",
        "        self.max_surname_length = max_surname_length\n",
        "\n",
        "    def vectorize(self, surname):\n",
        "        one_hot_matrix_size = (self.max_surname_length, len(self.surname_vocab))\n",
        "        one_hot_matrix = np.zeros(one_hot_matrix_size, dtype=np.float32)\n",
        "                               \n",
        "        for position_index, character in enumerate(surname):\n",
        "            character_index = self.surname_vocab.lookup_token(character)\n",
        "            one_hot_matrix[position_index][character_index] = 1\n",
        "        \n",
        "        return one_hot_matrix\n",
        "    \n",
        "    def unvectorize(self, one_hot_matrix):\n",
        "        len_name = int(np.sum(one_hot_matrix))\n",
        "        indices = np.zeros(len_name)\n",
        "        for i in range(len_name):\n",
        "            indices[i] = np.where(one_hot_matrix[i]==1)[0][0]\n",
        "        surname = [self.surname_vocab.lookup_index(index) for index in indices]\n",
        "        return surname\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, df):\n",
        "        surname_vocab = Vocabulary(add_unk=True)\n",
        "        nationality_vocab = Vocabulary(add_unk=False)\n",
        "        max_surname_length = 0\n",
        "\n",
        "        # Create vocabularies\n",
        "        for index, row in df.iterrows():\n",
        "            max_surname_length = max(max_surname_length, len(row.surname))\n",
        "            for letter in row.surname: # char-level tokenization\n",
        "                surname_vocab.add_token(letter)\n",
        "            nationality_vocab.add_token(row.nationality)\n",
        "        return cls(surname_vocab, nationality_vocab, max_surname_length)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        surname_vocab = Vocabulary.from_serializable(contents['surname_vocab'])\n",
        "        nationality_vocab =  Vocabulary.from_serializable(contents['nationality_vocab'])\n",
        "        return cls(surname_vocab, nationality_vocab, \n",
        "                   max_surname_length=contents['max_surname_length'])\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'surname_vocab': self.surname_vocab.to_serializable(),\n",
        "                'nationality_vocab': self.nationality_vocab.to_serializable(),\n",
        "                'max_surname_length': self.max_surname_length}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zq7RoFAXuBo9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a1a53b04-9aa8-4d35-8024-c201af256b11"
      },
      "cell_type": "code",
      "source": [
        "# Vectorizer instance\n",
        "vectorizer = SurnameVectorizer.from_dataframe(split_df)\n",
        "print (vectorizer.surname_vocab)\n",
        "print (vectorizer.nationality_vocab)\n",
        "vectorized_surname = vectorizer.vectorize(preprocess_text(\"goku\"))\n",
        "print (np.shape(vectorized_surname))\n",
        "print (vectorized_surname)\n",
        "print (vectorizer.unvectorize(vectorized_surname))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Vocabulary(size=85)>\n",
            "<Vocabulary(size=18)>\n",
            "(17, 85)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "['g', 'o', 'k', 'u']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mwD5PVkgZ-mt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The inputs into a CNN must all have the same shape. Therefore, we determine the largest surname and make sure that all names meet that max length. For shorter names, we pad it with zeros to meet the max length. "
      ]
    },
    {
      "metadata": {
        "id": "wwQ8MNp5ZfeG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Note**: Unlike the bagged ont-hot encoding method in the MLP notebook, we are able to preserve the semantic structure of the surnames. We are able to use one-hot encoding here because we are using characters but when we process text with large vocabularies, this method simply can't scale. We'll explore embedding based methods in subsequent notebooks. "
      ]
    },
    {
      "metadata": {
        "id": "Mnf7gXgKuOgp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ]
    },
    {
      "metadata": {
        "id": "YYqzM53fuBrf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gjolk855uPrA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SurnameDataset(Dataset):\n",
        "    def __init__(self, df, vectorizer):\n",
        "        self.df = df\n",
        "        self.vectorizer = vectorizer\n",
        "\n",
        "        # Data splits\n",
        "        self.train_df = self.df[self.df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "        self.val_df = self.df[self.df.split=='val']\n",
        "        self.val_size = len(self.val_df)\n",
        "        self.test_df = self.df[self.df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "        self.lookup_dict = {'train': (self.train_df, self.train_size), \n",
        "                            'val': (self.val_df, self.val_size),\n",
        "                            'test': (self.test_df, self.test_size)}\n",
        "        self.set_split('train')\n",
        "\n",
        "        # Class weights (for imbalances)\n",
        "        class_counts = df.nationality.value_counts().to_dict()\n",
        "        def sort_key(item):\n",
        "            return self.vectorizer.nationality_vocab.lookup_token(item[0])\n",
        "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
        "        frequencies = [count for _, count in sorted_counts]\n",
        "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, split_data_file):\n",
        "        df = pd.read_csv(split_data_file, header=0)\n",
        "        train_df = df[df.split=='train']\n",
        "        return cls(df, SurnameVectorizer.from_dataframe(train_df))\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, split_data_file, vectorizer_filepath):\n",
        "        df = pd.read_csv(split_data_file, header=0)\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(df, vectorizer)\n",
        "\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return SurnameVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self.vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        self.target_split = split\n",
        "        self.target_df, self.target_size = self.lookup_dict[split]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Dataset(split={0}, size={1})\".format(\n",
        "            self.target_split, self.target_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.target_df.iloc[index]\n",
        "        surname_vector = self.vectorizer.vectorize(row.surname)\n",
        "        nationality_index = self.vectorizer.nationality_vocab.lookup_token(row.nationality)\n",
        "        return {'surname': surname_vector, 'nationality': nationality_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        return len(self) // batch_size\n",
        "\n",
        "    def generate_batches(self, batch_size, shuffle=True, drop_last=True, device=\"cpu\"):\n",
        "        dataloader = DataLoader(dataset=self, batch_size=batch_size, \n",
        "                                shuffle=shuffle, drop_last=drop_last)\n",
        "        for data_dict in dataloader:\n",
        "            out_data_dict = {}\n",
        "            for name, tensor in data_dict.items():\n",
        "                out_data_dict[name] = data_dict[name].to(device)\n",
        "            yield out_data_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hvy-CJVSuPuS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "030900c3-7025-4224-b68d-28bf1c1151fb"
      },
      "cell_type": "code",
      "source": [
        "# Dataset instance\n",
        "dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.split_data_file)\n",
        "print (dataset) # __str__\n",
        "print (np.shape(dataset[5]['surname'])) # __getitem__\n",
        "print (dataset.class_weights)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Dataset(split=train, size=7680)\n",
            "(17, 51)\n",
            "tensor([0.0006, 0.0045, 0.0024, 0.0042, 0.0003, 0.0044, 0.0017, 0.0064, 0.0055,\n",
            "        0.0017, 0.0013, 0.0130, 0.0083, 0.0182, 0.0004, 0.0133, 0.0039, 0.0172])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XY0CqM2Rd3Im",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model"
      ]
    },
    {
      "metadata": {
        "id": "pWGpAzKPd32f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d7Q0_nkjd30L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SurnameModel(nn.Module):\n",
        "    def __init__(self, num_input_channels, num_channels, num_classes):\n",
        "        super(SurnameModel, self).__init__()\n",
        "        \n",
        "        # Conv weights\n",
        "        self.conv = nn.ModuleList([nn.Conv1d(num_input_channels, num_channels, \n",
        "                                             kernel_size=f) for f in [2,3,4]])\n",
        "     \n",
        "        # FC weights\n",
        "        self.fc1 = nn.Linear(num_channels*3, num_classes)\n",
        "\n",
        "    def forward(self, x_in, channel_first=False, apply_softmax=False):\n",
        "        \n",
        "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2)\n",
        "            \n",
        "        # Conv outputs\n",
        "        z1 = self.conv[0](x_in)\n",
        "        z1 = F.max_pool1d(z1, z1.size(2)).squeeze(2)\n",
        "        z2 = self.conv[1](x_in)\n",
        "        z2 = F.max_pool1d(z2, z2.size(2)).squeeze(2)\n",
        "        z3 = self.conv[2](x_in)\n",
        "        z3 = F.max_pool1d(z3, z3.size(2)).squeeze(2)\n",
        "        \n",
        "        # Concat conv outputs\n",
        "        z = torch.cat([z1, z2, z3], 1)\n",
        "\n",
        "        # FC layer\n",
        "        y_pred = self.fc1(z)\n",
        "        \n",
        "        if apply_softmax:\n",
        "            y_pred = F.softmax(y_pred, dim=1)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7XlJwSKQkL_C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "wLLmIuKRkNYW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sV-Dc_5ykNgS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, dataset, model, model_state_file, save_dir, device, shuffle, \n",
        "               num_epochs, batch_size, learning_rate, early_stopping_criteria):\n",
        "        self.dataset = dataset\n",
        "        self.class_weights = dataset.class_weights.to(device)\n",
        "        self.model = model.to(device)\n",
        "        self.save_dir = save_dir\n",
        "        self.device = device\n",
        "        self.shuffle = shuffle\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.loss_func = nn.CrossEntropyLoss(self.class_weights)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer=self.optimizer, mode='min', factor=0.5, patience=1)\n",
        "        self.train_state = {\n",
        "            'stop_early': False, \n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'early_stopping_criteria': early_stopping_criteria,\n",
        "            'learning_rate': learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': model_state_file}\n",
        "    \n",
        "    def update_train_state(self):\n",
        "\n",
        "        # Verbose\n",
        "        print (\"[EPOCH]: {0} | [LR]: {1} | [TRAIN LOSS]: {2:.2f} | [TRAIN ACC]: {3:.1f}% | [VAL LOSS]: {4:.2f} | [VAL ACC]: {5:.1f}%\".format(\n",
        "          self.train_state['epoch_index'], self.train_state['learning_rate'], \n",
        "            self.train_state['train_loss'][-1], self.train_state['train_acc'][-1], \n",
        "            self.train_state['val_loss'][-1], self.train_state['val_acc'][-1]))\n",
        "\n",
        "        # Save one model at least\n",
        "        if self.train_state['epoch_index'] == 0:\n",
        "            torch.save(self.model.state_dict(), self.train_state['model_filename'])\n",
        "            self.train_state['stop_early'] = False\n",
        "\n",
        "        # Save model if performance improved\n",
        "        elif self.train_state['epoch_index'] >= 1:\n",
        "            loss_tm1, loss_t = self.train_state['val_loss'][-2:]\n",
        "\n",
        "            # If loss worsened\n",
        "            if loss_t >= self.train_state['early_stopping_best_val']:\n",
        "                # Update step\n",
        "                self.train_state['early_stopping_step'] += 1\n",
        "\n",
        "            # Loss decreased\n",
        "            else:\n",
        "                # Save the best model\n",
        "                if loss_t < self.train_state['early_stopping_best_val']:\n",
        "                    torch.save(self.model.state_dict(), self.train_state['model_filename'])\n",
        "\n",
        "                # Reset early stopping step\n",
        "                self.train_state['early_stopping_step'] = 0\n",
        "\n",
        "            # Stop early ?\n",
        "            self.train_state['stop_early'] = self.train_state['early_stopping_step'] \\\n",
        "              >= self.train_state['early_stopping_criteria']\n",
        "        return self.train_state\n",
        "  \n",
        "    def compute_accuracy(self, y_pred, y_target):\n",
        "        _, y_pred_indices = y_pred.max(dim=1)\n",
        "        n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "        return n_correct / len(y_pred_indices) * 100\n",
        "  \n",
        "    def run_train_loop(self):\n",
        "        for epoch_index in range(self.num_epochs):\n",
        "            self.train_state['epoch_index'] = epoch_index\n",
        "      \n",
        "            # Iterate over train dataset\n",
        "\n",
        "            # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "            self.dataset.set_split('train')\n",
        "            batch_generator = self.dataset.generate_batches(\n",
        "                batch_size=self.batch_size, shuffle=self.shuffle, \n",
        "                device=self.device)\n",
        "            running_loss = 0.0\n",
        "            running_acc = 0.0\n",
        "            self.model.train()\n",
        "\n",
        "            for batch_index, batch_dict in enumerate(batch_generator):\n",
        "                # the training routine is these 5 steps:\n",
        "\n",
        "                # --------------------------------------\n",
        "                # step 1. zero the gradients\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # step 2. compute the output\n",
        "                y_pred = self.model(batch_dict['surname'])\n",
        "\n",
        "                # step 3. compute the loss\n",
        "                loss = self.loss_func(y_pred, batch_dict['nationality'])\n",
        "                loss_t = loss.item()\n",
        "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "                # step 4. use loss to produce gradients\n",
        "                loss.backward()\n",
        "\n",
        "                # step 5. use optimizer to take gradient step\n",
        "                self.optimizer.step()\n",
        "                # -----------------------------------------\n",
        "                # compute the accuracy\n",
        "                acc_t = self.compute_accuracy(y_pred, batch_dict['nationality'])\n",
        "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            self.train_state['train_loss'].append(running_loss)\n",
        "            self.train_state['train_acc'].append(running_acc)\n",
        "\n",
        "            # Iterate over val dataset\n",
        "\n",
        "            # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "            self.dataset.set_split('val')\n",
        "            batch_generator = self.dataset.generate_batches(\n",
        "                batch_size=self.batch_size, shuffle=self.shuffle, device=self.device)\n",
        "            running_loss = 0.\n",
        "            running_acc = 0.\n",
        "            self.model.eval()\n",
        "\n",
        "            for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "                # compute the output\n",
        "                y_pred =  self.model(batch_dict['surname'])\n",
        "\n",
        "                # step 3. compute the loss\n",
        "                loss = self.loss_func(y_pred, batch_dict['nationality'])\n",
        "                loss_t = loss.to(\"cpu\").item()\n",
        "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "                # compute the accuracy\n",
        "                acc_t = self.compute_accuracy(y_pred, batch_dict['nationality'])\n",
        "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            self.train_state['val_loss'].append(running_loss)\n",
        "            self.train_state['val_acc'].append(running_acc)\n",
        "\n",
        "            self.train_state = self.update_train_state()\n",
        "            self.scheduler.step(self.train_state['val_loss'][-1])\n",
        "            if self.train_state['stop_early']:\n",
        "                break\n",
        "          \n",
        "    def run_test_loop(self):\n",
        "        self.dataset.set_split('test')\n",
        "        batch_generator = self.dataset.generate_batches(\n",
        "            batch_size=self.batch_size, shuffle=self.shuffle, device=self.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        self.model.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # compute the output\n",
        "            y_pred =  self.model(batch_dict['surname'])\n",
        "\n",
        "            # compute the loss\n",
        "            loss = self.loss_func(y_pred, batch_dict['nationality'])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # compute the accuracy\n",
        "            acc_t = self.compute_accuracy(y_pred, batch_dict['nationality'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "        self.train_state['test_loss'] = running_loss\n",
        "        self.train_state['test_acc'] = running_acc\n",
        "    \n",
        "    def plot_performance(self):\n",
        "        # Figure size\n",
        "        plt.figure(figsize=(15,5))\n",
        "\n",
        "        # Plot Loss\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(\"Loss\")\n",
        "        plt.plot(trainer.train_state[\"train_loss\"], label=\"train\")\n",
        "        plt.plot(trainer.train_state[\"val_loss\"], label=\"val\")\n",
        "        plt.legend(loc='upper right')\n",
        "\n",
        "        # Plot Accuracy\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(\"Accuracy\")\n",
        "        plt.plot(trainer.train_state[\"train_acc\"], label=\"train\")\n",
        "        plt.plot(trainer.train_state[\"val_acc\"], label=\"val\")\n",
        "        plt.legend(loc='lower right')\n",
        "\n",
        "        # Save figure\n",
        "        plt.savefig(os.path.join(self.save_dir, \"performance.png\"))\n",
        "\n",
        "        # Show plots\n",
        "        plt.show()\n",
        "    \n",
        "    def save_train_state(self):\n",
        "        with open(os.path.join(self.save_dir, \"train_state.json\"), \"w\") as fp:\n",
        "            json.dump(self.train_state, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OkeOQRwckNd1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67236699-d49a-42b6-b8b8-342a67c155e8"
      },
      "cell_type": "code",
      "source": [
        "# Initialization\n",
        "if args.reload_from_files:\n",
        "    print (\"Reloading!\")\n",
        "    dataset = SurnameDataset.load_dataset_and_load_vectorizer(\n",
        "        args.split_data_file,args.vectorizer_file)\n",
        "else:\n",
        "    print (\"Creating from scratch!\")\n",
        "    dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.split_data_file)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "vectorizer = dataset.vectorizer\n",
        "model = SurnameModel(num_input_channels=len(vectorizer.surname_vocab),\n",
        "                     num_channels=args.num_filters\n",
        "                     num_classes=len(vectorizer.nationality_vocab))\n",
        "print (model.named_modules)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating from scratch!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3JJdOO4ZkNb3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e6cdb7a8-3d64-40fc-cf26-a1d5dcdf6e5c"
      },
      "cell_type": "code",
      "source": [
        "# Train\n",
        "trainer = Trainer(dataset=dataset, model=model, \n",
        "                  model_state_file=args.model_state_file, \n",
        "                  save_dir=args.save_dir, device=args.device,\n",
        "                  shuffle=args.shuffle, num_epochs=args.num_epochs, \n",
        "                  batch_size=args.batch_size, learning_rate=args.learning_rate, \n",
        "                  early_stopping_criteria=args.early_stopping_criteria)\n",
        "trainer.run_train_loop()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[EPOCH]: 0 | [LR]: 0.001 | [TRAIN LOSS]: 2.81 | [TRAIN ACC]: 29.6% | [VAL LOSS]: 2.67 | [VAL ACC]: 42.1%\n",
            "[EPOCH]: 1 | [LR]: 0.001 | [TRAIN LOSS]: 2.43 | [TRAIN ACC]: 46.4% | [VAL LOSS]: 2.26 | [VAL ACC]: 46.6%\n",
            "[EPOCH]: 2 | [LR]: 0.001 | [TRAIN LOSS]: 2.02 | [TRAIN ACC]: 50.6% | [VAL LOSS]: 1.96 | [VAL ACC]: 47.2%\n",
            "[EPOCH]: 3 | [LR]: 0.001 | [TRAIN LOSS]: 1.72 | [TRAIN ACC]: 54.6% | [VAL LOSS]: 1.76 | [VAL ACC]: 52.8%\n",
            "[EPOCH]: 4 | [LR]: 0.001 | [TRAIN LOSS]: 1.51 | [TRAIN ACC]: 58.7% | [VAL LOSS]: 1.62 | [VAL ACC]: 58.8%\n",
            "[EPOCH]: 5 | [LR]: 0.001 | [TRAIN LOSS]: 1.35 | [TRAIN ACC]: 62.0% | [VAL LOSS]: 1.52 | [VAL ACC]: 57.9%\n",
            "[EPOCH]: 6 | [LR]: 0.001 | [TRAIN LOSS]: 1.22 | [TRAIN ACC]: 64.3% | [VAL LOSS]: 1.47 | [VAL ACC]: 61.6%\n",
            "[EPOCH]: 7 | [LR]: 0.001 | [TRAIN LOSS]: 1.12 | [TRAIN ACC]: 65.5% | [VAL LOSS]: 1.38 | [VAL ACC]: 61.9%\n",
            "[EPOCH]: 8 | [LR]: 0.001 | [TRAIN LOSS]: 1.04 | [TRAIN ACC]: 67.6% | [VAL LOSS]: 1.34 | [VAL ACC]: 61.9%\n",
            "[EPOCH]: 9 | [LR]: 0.001 | [TRAIN LOSS]: 0.96 | [TRAIN ACC]: 69.2% | [VAL LOSS]: 1.30 | [VAL ACC]: 63.8%\n",
            "[EPOCH]: 10 | [LR]: 0.001 | [TRAIN LOSS]: 0.88 | [TRAIN ACC]: 70.6% | [VAL LOSS]: 1.31 | [VAL ACC]: 65.1%\n",
            "[EPOCH]: 11 | [LR]: 0.001 | [TRAIN LOSS]: 0.82 | [TRAIN ACC]: 71.7% | [VAL LOSS]: 1.28 | [VAL ACC]: 64.9%\n",
            "[EPOCH]: 12 | [LR]: 0.001 | [TRAIN LOSS]: 0.77 | [TRAIN ACC]: 72.9% | [VAL LOSS]: 1.27 | [VAL ACC]: 67.9%\n",
            "[EPOCH]: 13 | [LR]: 0.001 | [TRAIN LOSS]: 0.72 | [TRAIN ACC]: 74.1% | [VAL LOSS]: 1.22 | [VAL ACC]: 67.7%\n",
            "[EPOCH]: 14 | [LR]: 0.001 | [TRAIN LOSS]: 0.68 | [TRAIN ACC]: 74.9% | [VAL LOSS]: 1.25 | [VAL ACC]: 68.2%\n",
            "[EPOCH]: 15 | [LR]: 0.001 | [TRAIN LOSS]: 0.64 | [TRAIN ACC]: 75.5% | [VAL LOSS]: 1.24 | [VAL ACC]: 69.8%\n",
            "[EPOCH]: 16 | [LR]: 0.001 | [TRAIN LOSS]: 0.59 | [TRAIN ACC]: 77.3% | [VAL LOSS]: 1.20 | [VAL ACC]: 69.3%\n",
            "[EPOCH]: 17 | [LR]: 0.001 | [TRAIN LOSS]: 0.57 | [TRAIN ACC]: 77.4% | [VAL LOSS]: 1.23 | [VAL ACC]: 70.6%\n",
            "[EPOCH]: 18 | [LR]: 0.001 | [TRAIN LOSS]: 0.56 | [TRAIN ACC]: 78.2% | [VAL LOSS]: 1.24 | [VAL ACC]: 70.1%\n",
            "[EPOCH]: 19 | [LR]: 0.001 | [TRAIN LOSS]: 0.54 | [TRAIN ACC]: 78.2% | [VAL LOSS]: 1.26 | [VAL ACC]: 70.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0QLZfEyznVpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "a4bdd587-5f57-4976-e3d6-0ccfae91a2bb"
      },
      "cell_type": "code",
      "source": [
        "# Plot performance\n",
        "trainer.plot_performance()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2gAAAE+CAYAAAD4XjP+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\np9Ik1gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9e08ea1da0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "BWGzMSaBnYMb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "07e3585c-867d-4dce-d2c2-ea996fcb69b0"
      },
      "cell_type": "code",
      "source": [
        "# Test performance\n",
        "trainer.run_test_loop()\n",
        "print(\"Test loss: {0:.2f}\".format(trainer.train_state['test_loss']))\n",
        "print(\"Test Accuracy: {0:.1f}%\".format(trainer.train_state['test_acc']))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.28\n",
            "Test Accuracy: 69.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5672VEginYnY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save all results\n",
        "trainer.save_train_state()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HN1g2vP3nad_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ]
    },
    {
      "metadata": {
        "id": "Myr8QQjKnZ7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Inference(object):\n",
        "    def __init__(self, model, vectorizer):\n",
        "        self.model = model\n",
        "        self.vectorizer = vectorizer\n",
        "  \n",
        "    def predict_nationality(self, surname):\n",
        "        # Forward pass\n",
        "        vectorized_surname = torch.tensor(self.vectorizer.vectorize(surname)).unsqueeze(0)\n",
        "        self.model.eval()\n",
        "        y_pred = self.model(vectorized_surname, apply_softmax=True)\n",
        "\n",
        "        # Top nationality\n",
        "        y_prob, indices = y_pred.max(dim=1)\n",
        "        index = indices.item()\n",
        "\n",
        "        # Predicted nationality\n",
        "        nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
        "        probability = y_prob.item()\n",
        "        return {'nationality': nationality, 'probability': probability}\n",
        "  \n",
        "    def predict_top_k(self, surname, k):\n",
        "        # Forward pass\n",
        "        vectorized_surname = torch.tensor(self.vectorizer.vectorize(surname)).unsqueeze(0)\n",
        "        self.model.eval()\n",
        "        y_pred = self.model(vectorized_surname, apply_softmax=True)\n",
        "\n",
        "        # Top k nationalities\n",
        "        y_prob, indices = torch.topk(y_pred, k=k)\n",
        "        probabilities = y_prob.detach().numpy()[0]\n",
        "        indices = indices.detach().numpy()[0]\n",
        "\n",
        "        # Results\n",
        "        results = []\n",
        "        for probability, index in zip(probabilities, indices):\n",
        "            nationality = self.vectorizer.nationality_vocab.lookup_index(index)\n",
        "            results.append({'nationality': nationality, 'probability': probability})\n",
        "\n",
        "        return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vV2SBrXpdllN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fa74d36-25f3-4125-db88-fcd556d8f6c0"
      },
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "print (\"Reloading!\")\n",
        "dataset = SurnameDataset.load_dataset_and_load_vectorizer(\n",
        "    args.split_data_file, args.vectorizer_file)\n",
        "vectorizer = dataset.vectorizer\n",
        "model = SurnameModel(num_input_channels=len(vectorizer.surname_vocab),\n",
        "                     num_channels=args.num_filters\n",
        "                     num_classes=len(vectorizer.nationality_vocab))\n",
        "model.load_state_dict(torch.load(args.model_state_file))\n",
        "model = model.to(args.device)\n",
        "print (model.named_modules)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reloading!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TRc5KCZinaBh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "908d0c59-136c-4baa-c29c-1b96402e5429"
      },
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "inference = Inference(model=model, vectorizer=vectorizer)\n",
        "surname = input(\"Enter a surname to classify: \")\n",
        "prediction = inference.predict_nationality(preprocess_text(surname))\n",
        "print(\"{} -> {} (p={:0.2f})\".format(surname, prediction['nationality'], \n",
        "                                    prediction['probability']))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a surname to classify: Goku\n",
            "Goku -> Japanese (p=0.98)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P5slsQKwnZ_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b263fb67-a821-46ab-acdf-d534cb08be2e"
      },
      "cell_type": "code",
      "source": [
        "# Top-k inference\n",
        "top_k = inference.predict_top_k(preprocess_text(surname), k=3)\n",
        "for result in top_k:\n",
        "    print (\"{} -> {} (p={:0.2f})\".format(surname, result['nationality'], \n",
        "                                         result['probability']))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Goku -> Japanese (p=0.98)\n",
            "Goku -> Korean (p=0.01)\n",
            "Goku -> Czech (p=0.00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w6WRq-O3d1ba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TODO"
      ]
    },
    {
      "metadata": {
        "id": "oEcbaRswd1d0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* image classification example\n",
        "* segmentation\n",
        "* deep CNN architectures\n",
        "* small 3X3 filters\n",
        "* details on padding and stride (control receptive field, make every pixel the center of the filter, etc.)\n",
        "* network-in-network (1x1 conv)\n",
        "* residual connections / residual block\n",
        "* interpretability (which n-grams fire)"
      ]
    }
  ]
}