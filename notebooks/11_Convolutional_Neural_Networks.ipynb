{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11_Convolutional_Neural_Networks",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "bOChJSNXtC9g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks (CNN)"
      ]
    },
    {
      "metadata": {
        "id": "OLIxEDq6VhvZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/logo.png\" width=150>\n",
        "\n",
        "In this lesson we will learn the basics of CNNs applied to image and text based data sources.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "VoMq0eFRvugb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Overview"
      ]
    },
    {
      "metadata": {
        "id": "ziGJNhiQeiGN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/cnn.png\" width=700>"
      ]
    },
    {
      "metadata": {
        "id": "qWro5T5qTJJL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* **Objective:**  Detect spatial substructure from input data to aid in classification, segmentation, etc.\n",
        "* **Advantages:** \n",
        "  * Small number of weights (shared)\n",
        "  * Parallelizable\n",
        "  * Detects spatial substrcutures (feature extractors)\n",
        "  * Interpretable via filters\n",
        "  * Used for in images/text/time-series etc.\n",
        "* **Disadvantages:**\n",
        "  * Many hyperparameters (kernel size, strides, etc.)\n",
        "  * Inputs have to be of same width (image dimensions, text length, etc.)\n",
        "* **Miscellaneous:** \n",
        "  * Lot's of deep CNN architectures constantly updated for SOTA performance"
      ]
    },
    {
      "metadata": {
        "id": "8nCsZGyWhI9f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Filters"
      ]
    },
    {
      "metadata": {
        "id": "lxpgRzIjiVHv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "At the core of CNNs are filters (weights, kernels, etc.) which convolve (slide) across our input to extract relevante features. The filters are initialized randomly but learn to pick up meaningful features from the input that aid in optimizing for the objective. We're going to teach CNNs in an unorthodox method where we entirely focus on applying it to 2D text data. Each input is composed of words and we will be representing each word as on-hot encoded vector which gives us our 2D input.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/conv.gif\" width=400>"
      ]
    },
    {
      "metadata": {
        "id": "1kTABJyYj91S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loading PyTorch library\n",
        "!pip3 install http://download.pytorch.org/whl/cpu/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kz9D2rrdmSl9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CFEbPKZFmSoZ",
        "colab_type": "code",
        "outputId": "d2ef58c6-c9bb-41a8-c6be-916a60357ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Assume all our inputs have the same # of words\n",
        "batch_size = 128\n",
        "sequence_size = 10 # words per input\n",
        "one_hot_size = 20 # vocab size\n",
        "x = torch.randn(batch_size, one_hot_size, sequence_size)\n",
        "print(\"Size: {}\".format(x.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([128, 20, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8V4y9D75mSrA",
        "colab_type": "code",
        "outputId": "9b58e69a-6f2a-4f81-9600-7f2ddaf9b338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# Create filters for a conv layer\n",
        "out_channels = 96 # of filters\n",
        "kernel_size = 3 # filters are 3X3\n",
        "conv1 = nn.Conv1d(in_channels=one_hot_size, out_channels=out_channels, kernel_size=kernel_size)\n",
        "print(\"Size: {}\".format(conv1.weight.shape))\n",
        "print(\"Filter size: {}\".format(conv1.out_channels))\n",
        "print(\"Filter size: {}\".format(conv1.kernel_size[0]))\n",
        "print(\"Padding: {}\".format(conv1.padding[0]))\n",
        "print(\"Stride: {}\".format(conv1.stride[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([96, 20, 3])\n",
            "Filter size: 96\n",
            "Filter size: 3\n",
            "Padding: 0\n",
            "Stride: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x40mC6Q3mStp",
        "colab_type": "code",
        "outputId": "f77ff817-b917-492f-b921-1cdaddec239e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Convolve using filters\n",
        "conv_output = conv1(x)\n",
        "print(\"Size: {}\".format(conv_output.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([128, 96, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WE9ntwKOsZky",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We get 128 for the batch size, 96 outputs because that's how many filters we used on the input, but where is the 8 coming from? You can visually apply the convolution or use this handy equation:\n",
        "\n",
        "$\\frac{W - F + 2P}{S} + 1 = \\frac{10 - 3 + 2(0)}{1} + 1 = 8$\n",
        "\n",
        "where:\n",
        "  * W: width of each input\n",
        "  * F: filter size\n",
        "  * P: padding\n",
        "  * S: stride"
      ]
    },
    {
      "metadata": {
        "id": "vwTtF7bBuZvF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pooling"
      ]
    },
    {
      "metadata": {
        "id": "VXBbKPs1ua9G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The result of convolving filters on an input is a feature map. Due to the nature of convolution and overlaps, our feature map will have lots of redundant information. Pooling is a way to summarize a high-dimensional feature map into a lower dimensional one for simplified downstream computation. The pooling operation can be the max value, average, etc. in a certain receptive field.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/pool.jpeg\" width=450>"
      ]
    },
    {
      "metadata": {
        "id": "VCag6lk2mSwU",
        "colab_type": "code",
        "outputId": "aa37c395-b8cb-452a-c561-d593f3f0d73b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Max pooling\n",
        "kernel_size = 2\n",
        "pool1 = nn.MaxPool1d(kernel_size=kernel_size, stride=2, padding=0)\n",
        "pool_output = pool1(conv_output)\n",
        "print(\"Size: {}\".format(pool_output.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([128, 96, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c_e4QRFwvTt8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$\\frac{W-F}{S} + 1 = \\frac{8-2}{2} + 1 = 4$"
      ]
    },
    {
      "metadata": {
        "id": "l9rL1EWIfi-y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNNs on text"
      ]
    },
    {
      "metadata": {
        "id": "aWtHDOJgHZvk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We're going use convolutional neural networks on text data which involves convolving on the character level. This could invovle: \n",
        "\n",
        "* 1D conv operations where inputs are words | $\\in \\mathbb{R}^{NXWXE}$\n",
        "    * where:\n",
        "    * N = batchsize\n",
        "    * W = max word length \n",
        "    * E = vocab_size (or embedding dim) at a char level\n",
        "    \n",
        "* 2D conv operations where inputs are sentences | $\\in \\mathbb{R}^{NXSXWXE}$\n",
        "    * where:\n",
        "    * N = batchsize\n",
        "    * S = max sentence length\n",
        "    * W = max word length \n",
        "    * E = vocab_size (or embedding dim) at a char level\n",
        "\n",
        "You can easily use this set up for [time series](https://arxiv.org/abs/1807.10707) data or [combine it](https://arxiv.org/abs/1808.04928) with other networks. For text data, we will create filters of varying kernel sizes (2, 3, 4) which act as feature selectors of varying n-gram sizes. The outputs are concated and fed into a fully-connected layer for class predictions. \n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/cnn_text.jpg\" width=650>"
      ]
    },
    {
      "metadata": {
        "id": "bVBZxbaAtS9u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ]
    },
    {
      "metadata": {
        "id": "y8QSdEcDtXUs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "import collections\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VADCXjMwtXYN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set Numpy and PyTorch seeds\n",
        "def set_seeds(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        \n",
        "# Creating directories\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mpiCYECstXbT",
        "colab_type": "code",
        "outputId": "1a839433-7ca6-4361-c1c2-a88118d53056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# Arguments\n",
        "args = Namespace(\n",
        "    seed=1234,\n",
        "    cuda=False,\n",
        "    shuffle=True,\n",
        "    data_file=\"names.csv\",\n",
        "    split_data_file=\"split_names.csv\",\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"names\",\n",
        "    reload_from_files=False,\n",
        "    train_size=0.7,\n",
        "    val_size=0.15,\n",
        "    test_size=0.15,\n",
        "    num_epochs=20,\n",
        "    early_stopping_criteria=5,\n",
        "    learning_rate=1e-3,\n",
        "    batch_size=64,\n",
        "    num_filters=100,\n",
        "    dropout_p=0.1,\n",
        ")\n",
        "\n",
        "# Set seeds\n",
        "set_seeds(seed=args.seed, cuda=args.cuda)\n",
        "\n",
        "# Create save dir\n",
        "handle_dirs(args.save_dir)\n",
        "\n",
        "# Expand filepaths\n",
        "args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\n",
        "args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
        "print(\"Expanded filepaths: \")\n",
        "print(\"\\t{}\".format(args.vectorizer_file))\n",
        "print(\"\\t{}\".format(args.model_state_file))\n",
        "\n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "print(\"Using CUDA: {}\".format(args.cuda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\tnames/vectorizer.json\n",
            "\tnames/model.pth\n",
            "Using CUDA: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ptb4hJ4Bw8YU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data"
      ]
    },
    {
      "metadata": {
        "id": "bNxZQUqfmS0B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MBdQpUTQtMgu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Upload data from GitHub to notebook's local drive\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/data/surnames.csv\"\n",
        "response = urllib.request.urlopen(url)\n",
        "html = response.read()\n",
        "with open(args.data_file, 'wb') as fp:\n",
        "    fp.write(html)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6PYCeGrStMj7",
        "colab_type": "code",
        "outputId": "29fa5b79-4d63-4547-eaba-cca5a99355a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Raw data\n",
        "df = pd.read_csv(args.data_file, header=0)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>surname</th>\n",
              "      <th>nationality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Woodford</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Coté</td>\n",
              "      <td>French</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kore</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Koury</td>\n",
              "      <td>Arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lebzak</td>\n",
              "      <td>Russian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    surname nationality\n",
              "0  Woodford     English\n",
              "1      Coté      French\n",
              "2      Kore     English\n",
              "3     Koury      Arabic\n",
              "4    Lebzak     Russian"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "pbfVM-YatMnD",
        "colab_type": "code",
        "outputId": "1e76cdd2-a586-45de-b008-747c2d3ab6fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "# Split by nationality\n",
        "by_nationality = collections.defaultdict(list)\n",
        "for _, row in df.iterrows():\n",
        "    by_nationality[row.nationality].append(row.to_dict())\n",
        "for nationality in by_nationality:\n",
        "    print (\"{0}: {1}\".format(nationality, len(by_nationality[nationality])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English: 2972\n",
            "French: 229\n",
            "Arabic: 1603\n",
            "Russian: 2373\n",
            "Japanese: 775\n",
            "Chinese: 220\n",
            "Italian: 600\n",
            "Czech: 414\n",
            "Irish: 183\n",
            "German: 576\n",
            "Greek: 156\n",
            "Spanish: 258\n",
            "Polish: 120\n",
            "Dutch: 236\n",
            "Vietnamese: 58\n",
            "Korean: 77\n",
            "Portuguese: 55\n",
            "Scottish: 75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KdGOoKFjtMpz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create split data\n",
        "final_list = []\n",
        "for _, item_list in sorted(by_nationality.items()):\n",
        "    if args.shuffle:\n",
        "        np.random.shuffle(item_list)\n",
        "    n = len(item_list)\n",
        "    n_train = int(args.train_size*n)\n",
        "    n_val = int(args.val_size*n)\n",
        "    n_test = int(args.test_size*n)\n",
        "\n",
        "  # Give data point a split attribute\n",
        "    for item in item_list[:n_train]:\n",
        "        item['split'] = 'train'\n",
        "    for item in item_list[n_train:n_train+n_val]:\n",
        "        item['split'] = 'val'\n",
        "    for item in item_list[n_train+n_val:]:\n",
        "        item['split'] = 'test'  \n",
        "\n",
        "    # Add to final list\n",
        "    final_list.extend(item_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DyDwlzzKtMsz",
        "colab_type": "code",
        "outputId": "266c0846-fe63-4c47-8854-b883501d60b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# df with split datasets\n",
        "split_df = pd.DataFrame(final_list)\n",
        "split_df[\"split\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "train    7680\n",
              "test     1660\n",
              "val      1640\n",
              "Name: split, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "17aHMQOwtMvh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
        "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
        "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
        "    return text\n",
        "    \n",
        "split_df.surname = split_df.surname.apply(preprocess_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wh6D8qfQmS2c",
        "colab_type": "code",
        "outputId": "4528406f-4a21-48cc-98e3-ca938fe72ee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "split_df.to_csv(args.split_data_file, index=False)\n",
        "split_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nationality</th>\n",
              "      <th>split</th>\n",
              "      <th>surname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Arabic</td>\n",
              "      <td>train</td>\n",
              "      <td>bishara</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Arabic</td>\n",
              "      <td>train</td>\n",
              "      <td>nahas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Arabic</td>\n",
              "      <td>train</td>\n",
              "      <td>ghanem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Arabic</td>\n",
              "      <td>train</td>\n",
              "      <td>tannous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Arabic</td>\n",
              "      <td>train</td>\n",
              "      <td>mikhail</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  nationality  split  surname\n",
              "0      Arabic  train  bishara\n",
              "1      Arabic  train    nahas\n",
              "2      Arabic  train   ghanem\n",
              "3      Arabic  train  tannous\n",
              "4      Arabic  train  mikhail"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "6nZBgfQTuAA8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Vocabulary"
      ]
    },
    {
      "metadata": {
        "id": "TeRVQlRZuBgA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Vocabulary(object):\n",
        "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
        "\n",
        "        # Token to index\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self.token_to_idx = token_to_idx\n",
        "\n",
        "        # Index to token\n",
        "        self.idx_to_token = {idx: token \\\n",
        "                             for token, idx in self.token_to_idx.items()}\n",
        "        \n",
        "        # Add unknown token\n",
        "        self.add_unk = add_unk\n",
        "        self.unk_token = unk_token\n",
        "        if self.add_unk:\n",
        "            self.unk_index = self.add_token(self.unk_token)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'token_to_idx': self.token_to_idx,\n",
        "                'add_unk': self.add_unk, 'unk_token': self.unk_token}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        if token in self.token_to_idx:\n",
        "            index = self.token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self.token_to_idx)\n",
        "            self.token_to_idx[token] = index\n",
        "            self.idx_to_token[index] = token\n",
        "        return index\n",
        "\n",
        "    def add_tokens(self, tokens):\n",
        "        return [self.add_token[token] for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        if self.add_unk:\n",
        "            index = self.token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            index =  self.token_to_idx[token]\n",
        "        return index\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        if index not in self.idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self.idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bH8LMH9wuBi9",
        "colab_type": "code",
        "outputId": "79e707ee-d29f-48ec-bcd6-16dd3cb6764d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Vocabulary instance\n",
        "nationality_vocab = Vocabulary(add_unk=False)\n",
        "for index, row in df.iterrows():\n",
        "    nationality_vocab.add_token(row.nationality)\n",
        "print (nationality_vocab) # __str__\n",
        "print (nationality_vocab.lookup_token(\"English\"))\n",
        "print (nationality_vocab.lookup_index(0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Vocabulary(size=18)>\n",
            "0\n",
            "English\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "57a1lzHPuHHm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Vectorizer"
      ]
    },
    {
      "metadata": {
        "id": "MwS5BEV-uBlt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SurnameVectorizer(object):\n",
        "    def __init__(self, surname_vocab, nationality_vocab, max_surname_length):\n",
        "        self.surname_vocab = surname_vocab\n",
        "        self.nationality_vocab = nationality_vocab\n",
        "        self.max_surname_length = max_surname_length\n",
        "\n",
        "    def vectorize(self, surname):\n",
        "        one_hot_matrix_size = (self.max_surname_length, len(self.surname_vocab))\n",
        "        one_hot_matrix = np.zeros(one_hot_matrix_size, dtype=np.float32)\n",
        "                               \n",
        "        for position_index, character in enumerate(surname):\n",
        "            character_index = self.surname_vocab.lookup_token(character)\n",
        "            one_hot_matrix[position_index][character_index] = 1\n",
        "        \n",
        "        return one_hot_matrix\n",
        "    \n",
        "    def unvectorize(self, one_hot_matrix):\n",
        "        len_name = int(np.sum(one_hot_matrix))\n",
        "        indices = np.zeros(len_name)\n",
        "        for i in range(len_name):\n",
        "            indices[i] = np.where(one_hot_matrix[i]==1)[0][0]\n",
        "        surname = [self.surname_vocab.lookup_index(index) for index in indices]\n",
        "        return surname\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, df):\n",
        "        surname_vocab = Vocabulary(add_unk=True)\n",
        "        nationality_vocab = Vocabulary(add_unk=False)\n",
        "        max_surname_length = 0\n",
        "\n",
        "        # Create vocabularies\n",
        "        for index, row in df.iterrows():\n",
        "            max_surname_length = max(max_surname_length, len(row.surname))\n",
        "            for letter in row.surname: # char-level tokenization\n",
        "                surname_vocab.add_token(letter)\n",
        "            nationality_vocab.add_token(row.nationality)\n",
        "        return cls(surname_vocab, nationality_vocab, max_surname_length)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        surname_vocab = Vocabulary.from_serializable(contents['surname_vocab'])\n",
        "        nationality_vocab =  Vocabulary.from_serializable(contents['nationality_vocab'])\n",
        "        return cls(surname_vocab, nationality_vocab, \n",
        "                   max_surname_length=contents['max_surname_length'])\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'surname_vocab': self.surname_vocab.to_serializable(),\n",
        "                'nationality_vocab': self.nationality_vocab.to_serializable(),\n",
        "                'max_surname_length': self.max_surname_length}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zq7RoFAXuBo9",
        "colab_type": "code",
        "outputId": "62d4aac0-5fb2-4cea-cec9-76b15d88e3cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "cell_type": "code",
      "source": [
        "# Vectorizer instance\n",
        "vectorizer = SurnameVectorizer.from_dataframe(split_df)\n",
        "print (vectorizer.surname_vocab)\n",
        "print (vectorizer.nationality_vocab)\n",
        "vectorized_surname = vectorizer.vectorize(preprocess_text(\"goku\"))\n",
        "print (np.shape(vectorized_surname))\n",
        "print (vectorized_surname)\n",
        "print (vectorizer.unvectorize(vectorized_surname))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Vocabulary(size=28)>\n",
            "<Vocabulary(size=18)>\n",
            "(17, 28)\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]]\n",
            "['g', 'o', 'k', 'u']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mwD5PVkgZ-mt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The inputs into a CNN must all have the same shape. Therefore, we determine the largest surname and make sure that all names meet that max length. For shorter names, we pad it with zeros to meet the max length. "
      ]
    },
    {
      "metadata": {
        "id": "wwQ8MNp5ZfeG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Note**: Unlike the bagged ont-hot encoding method in the MLP notebook, we are able to preserve the semantic structure of the surnames. We are able to use one-hot encoding here because we are using characters but when we process text with large vocabularies, this method simply can't scale. We'll explore embedding based methods in subsequent notebooks. "
      ]
    },
    {
      "metadata": {
        "id": "Mnf7gXgKuOgp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ]
    },
    {
      "metadata": {
        "id": "YYqzM53fuBrf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gjolk855uPrA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SurnameDataset(Dataset):\n",
        "    def __init__(self, df, vectorizer):\n",
        "        self.df = df\n",
        "        self.vectorizer = vectorizer\n",
        "\n",
        "        # Data splits\n",
        "        self.train_df = self.df[self.df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "        self.val_df = self.df[self.df.split=='val']\n",
        "        self.val_size = len(self.val_df)\n",
        "        self.test_df = self.df[self.df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "        self.lookup_dict = {'train': (self.train_df, self.train_size), \n",
        "                            'val': (self.val_df, self.val_size),\n",
        "                            'test': (self.test_df, self.test_size)}\n",
        "        self.set_split('train')\n",
        "\n",
        "        # Class weights (for imbalances)\n",
        "        class_counts = df.nationality.value_counts().to_dict()\n",
        "        def sort_key(item):\n",
        "            return self.vectorizer.nationality_vocab.lookup_token(item[0])\n",
        "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
        "        frequencies = [count for _, count in sorted_counts]\n",
        "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, split_data_file):\n",
        "        df = pd.read_csv(split_data_file, header=0)\n",
        "        train_df = df[df.split=='train']\n",
        "        return cls(df, SurnameVectorizer.from_dataframe(train_df))\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, split_data_file, vectorizer_filepath):\n",
        "        df = pd.read_csv(split_data_file, header=0)\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(df, vectorizer)\n",
        "\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return SurnameVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self.vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        self.target_split = split\n",
        "        self.target_df, self.target_size = self.lookup_dict[split]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Dataset(split={0}, size={1})\".format(\n",
        "            self.target_split, self.target_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.target_df.iloc[index]\n",
        "        surname_vector = self.vectorizer.vectorize(row.surname)\n",
        "        nationality_index = self.vectorizer.nationality_vocab.lookup_token(row.nationality)\n",
        "        return {'surname': surname_vector, 'nationality': nationality_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        return len(self) // batch_size\n",
        "\n",
        "    def generate_batches(self, batch_size, shuffle=True, drop_last=True, device=\"cpu\"):\n",
        "        dataloader = DataLoader(dataset=self, batch_size=batch_size, \n",
        "                                shuffle=shuffle, drop_last=drop_last)\n",
        "        for data_dict in dataloader:\n",
        "            out_data_dict = {}\n",
        "            for name, tensor in data_dict.items():\n",
        "                out_data_dict[name] = data_dict[name].to(device)\n",
        "            yield out_data_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hvy-CJVSuPuS",
        "colab_type": "code",
        "outputId": "1175b39f-d0c3-4448-fe39-c08473938ed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# Dataset instance\n",
        "dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.split_data_file)\n",
        "print (dataset) # __str__\n",
        "print (np.shape(dataset[5]['surname'])) # __getitem__\n",
        "print (dataset.class_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Dataset(split=train, size=7680)\n",
            "(17, 28)\n",
            "tensor([0.0006, 0.0045, 0.0024, 0.0042, 0.0003, 0.0044, 0.0017, 0.0064, 0.0055,\n",
            "        0.0017, 0.0013, 0.0130, 0.0083, 0.0182, 0.0004, 0.0133, 0.0039, 0.0172])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XY0CqM2Rd3Im",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model"
      ]
    },
    {
      "metadata": {
        "id": "pWGpAzKPd32f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d7Q0_nkjd30L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SurnameModel(nn.Module):\n",
        "    def __init__(self, num_input_channels, num_channels, num_classes, dropout_p):\n",
        "        super(SurnameModel, self).__init__()\n",
        "        \n",
        "        # Conv weights\n",
        "        self.conv = nn.ModuleList([nn.Conv1d(num_input_channels, num_channels, \n",
        "                                             kernel_size=f) for f in [2,3,4]])\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "       \n",
        "        # FC weights\n",
        "        self.fc1 = nn.Linear(num_channels*3, num_classes)\n",
        "\n",
        "    def forward(self, x_in, channel_first=False, apply_softmax=False):\n",
        "        \n",
        "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2)\n",
        "            \n",
        "        # Conv outputs\n",
        "        z1 = self.conv[0](x_in)       \n",
        "        z1 = F.max_pool1d(z1, z1.size(2)).squeeze(2)\n",
        "        z2 = self.conv[1](x_in)\n",
        "        z2 = F.max_pool1d(z2, z2.size(2)).squeeze(2)\n",
        "        z3 = self.conv[2](x_in)\n",
        "        z3 = F.max_pool1d(z3, z3.size(2)).squeeze(2)        \n",
        "        \n",
        "        # Concat conv outputs\n",
        "        z = torch.cat([z1, z2, z3], 1)\n",
        "        z = self.dropout(z)\n",
        "\n",
        "        # FC layer\n",
        "        y_pred = self.fc1(z)\n",
        "        \n",
        "        if apply_softmax:\n",
        "            y_pred = F.softmax(y_pred, dim=1)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7XlJwSKQkL_C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "wLLmIuKRkNYW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sV-Dc_5ykNgS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, dataset, model, model_state_file, save_dir, device, shuffle, \n",
        "               num_epochs, batch_size, learning_rate, early_stopping_criteria):\n",
        "        self.dataset = dataset\n",
        "        self.class_weights = dataset.class_weights.to(device)\n",
        "        self.model = model.to(device)\n",
        "        self.save_dir = save_dir\n",
        "        self.device = device\n",
        "        self.shuffle = shuffle\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.loss_func = nn.CrossEntropyLoss(self.class_weights)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer=self.optimizer, mode='min', factor=0.5, patience=1)\n",
        "        self.train_state = {\n",
        "            'stop_early': False, \n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'early_stopping_criteria': early_stopping_criteria,\n",
        "            'learning_rate': learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': model_state_file}\n",
        "    \n",
        "    def update_train_state(self):\n",
        "\n",
        "        # Verbose\n",
        "        print (\"[EPOCH]: {0} | [LR]: {1} | [TRAIN LOSS]: {2:.2f} | [TRAIN ACC]: {3:.1f}% | [VAL LOSS]: {4:.2f} | [VAL ACC]: {5:.1f}%\".format(\n",
        "          self.train_state['epoch_index'], self.train_state['learning_rate'], \n",
        "            self.train_state['train_loss'][-1], self.train_state['train_acc'][-1], \n",
        "            self.train_state['val_loss'][-1], self.train_state['val_acc'][-1]))\n",
        "\n",
        "        # Save one model at least\n",
        "        if self.train_state['epoch_index'] == 0:\n",
        "            torch.save(self.model.state_dict(), self.train_state['model_filename'])\n",
        "            self.train_state['stop_early'] = False\n",
        "\n",
        "        # Save model if performance improved\n",
        "        elif self.train_state['epoch_index'] >= 1:\n",
        "            loss_tm1, loss_t = self.train_state['val_loss'][-2:]\n",
        "\n",
        "            # If loss worsened\n",
        "            if loss_t >= self.train_state['early_stopping_best_val']:\n",
        "                # Update step\n",
        "                self.train_state['early_stopping_step'] += 1\n",
        "\n",
        "            # Loss decreased\n",
        "            else:\n",
        "                # Save the best model\n",
        "                if loss_t < self.train_state['early_stopping_best_val']:\n",
        "                    torch.save(self.model.state_dict(), self.train_state['model_filename'])\n",
        "\n",
        "                # Reset early stopping step\n",
        "                self.train_state['early_stopping_step'] = 0\n",
        "\n",
        "            # Stop early ?\n",
        "            self.train_state['stop_early'] = self.train_state['early_stopping_step'] \\\n",
        "              >= self.train_state['early_stopping_criteria']\n",
        "        return self.train_state\n",
        "  \n",
        "    def compute_accuracy(self, y_pred, y_target):\n",
        "        _, y_pred_indices = y_pred.max(dim=1)\n",
        "        n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "        return n_correct / len(y_pred_indices) * 100\n",
        "  \n",
        "    def run_train_loop(self):\n",
        "        for epoch_index in range(self.num_epochs):\n",
        "            self.train_state['epoch_index'] = epoch_index\n",
        "      \n",
        "            # Iterate over train dataset\n",
        "\n",
        "            # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "            self.dataset.set_split('train')\n",
        "            batch_generator = self.dataset.generate_batches(\n",
        "                batch_size=self.batch_size, shuffle=self.shuffle, \n",
        "                device=self.device)\n",
        "            running_loss = 0.0\n",
        "            running_acc = 0.0\n",
        "            self.model.train()\n",
        "\n",
        "            for batch_index, batch_dict in enumerate(batch_generator):\n",
        "                # the training routine is these 5 steps:\n",
        "\n",
        "                # --------------------------------------\n",
        "                # step 1. zero the gradients\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # step 2. compute the output\n",
        "                y_pred = self.model(batch_dict['surname'])\n",
        "\n",
        "                # step 3. compute the loss\n",
        "                loss = self.loss_func(y_pred, batch_dict['nationality'])\n",
        "                loss_t = loss.item()\n",
        "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "                # step 4. use loss to produce gradients\n",
        "                loss.backward()\n",
        "\n",
        "                # step 5. use optimizer to take gradient step\n",
        "                self.optimizer.step()\n",
        "                # -----------------------------------------\n",
        "                # compute the accuracy\n",
        "                acc_t = self.compute_accuracy(y_pred, batch_dict['nationality'])\n",
        "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            self.train_state['train_loss'].append(running_loss)\n",
        "            self.train_state['train_acc'].append(running_acc)\n",
        "\n",
        "            # Iterate over val dataset\n",
        "\n",
        "            # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "            self.dataset.set_split('val')\n",
        "            batch_generator = self.dataset.generate_batches(\n",
        "                batch_size=self.batch_size, shuffle=self.shuffle, device=self.device)\n",
        "            running_loss = 0.\n",
        "            running_acc = 0.\n",
        "            self.model.eval()\n",
        "\n",
        "            for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "                # compute the output\n",
        "                y_pred =  self.model(batch_dict['surname'])\n",
        "\n",
        "                # step 3. compute the loss\n",
        "                loss = self.loss_func(y_pred, batch_dict['nationality'])\n",
        "                loss_t = loss.to(\"cpu\").item()\n",
        "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "                # compute the accuracy\n",
        "                acc_t = self.compute_accuracy(y_pred, batch_dict['nationality'])\n",
        "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            self.train_state['val_loss'].append(running_loss)\n",
        "            self.train_state['val_acc'].append(running_acc)\n",
        "\n",
        "            self.train_state = self.update_train_state()\n",
        "            self.scheduler.step(self.train_state['val_loss'][-1])\n",
        "            if self.train_state['stop_early']:\n",
        "                break\n",
        "          \n",
        "    def run_test_loop(self):\n",
        "        self.dataset.set_split('test')\n",
        "        batch_generator = self.dataset.generate_batches(\n",
        "            batch_size=self.batch_size, shuffle=self.shuffle, device=self.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        self.model.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # compute the output\n",
        "            y_pred =  self.model(batch_dict['surname'])\n",
        "\n",
        "            # compute the loss\n",
        "            loss = self.loss_func(y_pred, batch_dict['nationality'])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # compute the accuracy\n",
        "            acc_t = self.compute_accuracy(y_pred, batch_dict['nationality'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "        self.train_state['test_loss'] = running_loss\n",
        "        self.train_state['test_acc'] = running_acc\n",
        "    \n",
        "    def plot_performance(self):\n",
        "        # Figure size\n",
        "        plt.figure(figsize=(15,5))\n",
        "\n",
        "        # Plot Loss\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(\"Loss\")\n",
        "        plt.plot(trainer.train_state[\"train_loss\"], label=\"train\")\n",
        "        plt.plot(trainer.train_state[\"val_loss\"], label=\"val\")\n",
        "        plt.legend(loc='upper right')\n",
        "\n",
        "        # Plot Accuracy\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(\"Accuracy\")\n",
        "        plt.plot(trainer.train_state[\"train_acc\"], label=\"train\")\n",
        "        plt.plot(trainer.train_state[\"val_acc\"], label=\"val\")\n",
        "        plt.legend(loc='lower right')\n",
        "\n",
        "        # Save figure\n",
        "        plt.savefig(os.path.join(self.save_dir, \"performance.png\"))\n",
        "\n",
        "        # Show plots\n",
        "        plt.show()\n",
        "    \n",
        "    def save_train_state(self):\n",
        "        with open(os.path.join(self.save_dir, \"train_state.json\"), \"w\") as fp:\n",
        "            json.dump(self.train_state, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OkeOQRwckNd1",
        "colab_type": "code",
        "outputId": "90b9f3e4-1692-4d79-f792-ea737e5423b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "# Initialization\n",
        "if args.reload_from_files:\n",
        "    print (\"Reloading!\")\n",
        "    dataset = SurnameDataset.load_dataset_and_load_vectorizer(\n",
        "        args.split_data_file,args.vectorizer_file)\n",
        "else:\n",
        "    print (\"Creating from scratch!\")\n",
        "    dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.split_data_file)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "vectorizer = dataset.vectorizer\n",
        "model = SurnameModel(num_input_channels=len(vectorizer.surname_vocab),\n",
        "                     num_channels=args.num_filters,\n",
        "                     num_classes=len(vectorizer.nationality_vocab),\n",
        "                     dropout_p=args.dropout_p)\n",
        "print (model.named_modules)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating from scratch!\n",
            "<bound method Module.named_modules of SurnameModel(\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(28, 100, kernel_size=(2,), stride=(1,))\n",
            "    (1): Conv1d(28, 100, kernel_size=(3,), stride=(1,))\n",
            "    (2): Conv1d(28, 100, kernel_size=(4,), stride=(1,))\n",
            "  )\n",
            "  (conv_bn): ModuleList(\n",
            "    (0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1)\n",
            "  (fc1): Linear(in_features=300, out_features=18, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3JJdOO4ZkNb3",
        "colab_type": "code",
        "outputId": "c5c48a2b-7859-4857-846b-bdea62800e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "# Train\n",
        "trainer = Trainer(dataset=dataset, model=model, \n",
        "                  model_state_file=args.model_state_file, \n",
        "                  save_dir=args.save_dir, device=args.device,\n",
        "                  shuffle=args.shuffle, num_epochs=args.num_epochs, \n",
        "                  batch_size=args.batch_size, learning_rate=args.learning_rate, \n",
        "                  early_stopping_criteria=args.early_stopping_criteria)\n",
        "trainer.run_train_loop()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[EPOCH]: 0 | [LR]: 0.001 | [TRAIN LOSS]: 2.68 | [TRAIN ACC]: 21.8% | [VAL LOSS]: 2.32 | [VAL ACC]: 53.6%\n",
            "[EPOCH]: 1 | [LR]: 0.001 | [TRAIN LOSS]: 2.02 | [TRAIN ACC]: 43.7% | [VAL LOSS]: 1.99 | [VAL ACC]: 52.8%\n",
            "[EPOCH]: 2 | [LR]: 0.001 | [TRAIN LOSS]: 1.61 | [TRAIN ACC]: 51.5% | [VAL LOSS]: 1.76 | [VAL ACC]: 59.6%\n",
            "[EPOCH]: 3 | [LR]: 0.001 | [TRAIN LOSS]: 1.35 | [TRAIN ACC]: 56.6% | [VAL LOSS]: 1.73 | [VAL ACC]: 67.1%\n",
            "[EPOCH]: 4 | [LR]: 0.001 | [TRAIN LOSS]: 1.14 | [TRAIN ACC]: 60.6% | [VAL LOSS]: 1.58 | [VAL ACC]: 64.8%\n",
            "[EPOCH]: 5 | [LR]: 0.001 | [TRAIN LOSS]: 1.03 | [TRAIN ACC]: 63.4% | [VAL LOSS]: 1.55 | [VAL ACC]: 71.1%\n",
            "[EPOCH]: 6 | [LR]: 0.001 | [TRAIN LOSS]: 0.91 | [TRAIN ACC]: 66.6% | [VAL LOSS]: 1.54 | [VAL ACC]: 71.6%\n",
            "[EPOCH]: 7 | [LR]: 0.001 | [TRAIN LOSS]: 0.83 | [TRAIN ACC]: 68.2% | [VAL LOSS]: 1.49 | [VAL ACC]: 69.8%\n",
            "[EPOCH]: 8 | [LR]: 0.001 | [TRAIN LOSS]: 0.75 | [TRAIN ACC]: 70.0% | [VAL LOSS]: 1.55 | [VAL ACC]: 71.2%\n",
            "[EPOCH]: 9 | [LR]: 0.001 | [TRAIN LOSS]: 0.69 | [TRAIN ACC]: 70.7% | [VAL LOSS]: 1.50 | [VAL ACC]: 72.1%\n",
            "[EPOCH]: 10 | [LR]: 0.001 | [TRAIN LOSS]: 0.61 | [TRAIN ACC]: 73.8% | [VAL LOSS]: 1.54 | [VAL ACC]: 74.1%\n",
            "[EPOCH]: 11 | [LR]: 0.001 | [TRAIN LOSS]: 0.58 | [TRAIN ACC]: 74.9% | [VAL LOSS]: 1.49 | [VAL ACC]: 74.8%\n",
            "[EPOCH]: 12 | [LR]: 0.001 | [TRAIN LOSS]: 0.54 | [TRAIN ACC]: 75.2% | [VAL LOSS]: 1.49 | [VAL ACC]: 74.8%\n",
            "[EPOCH]: 13 | [LR]: 0.001 | [TRAIN LOSS]: 0.52 | [TRAIN ACC]: 76.0% | [VAL LOSS]: 1.60 | [VAL ACC]: 73.9%\n",
            "[EPOCH]: 14 | [LR]: 0.001 | [TRAIN LOSS]: 0.52 | [TRAIN ACC]: 76.0% | [VAL LOSS]: 1.63 | [VAL ACC]: 75.7%\n",
            "[EPOCH]: 15 | [LR]: 0.001 | [TRAIN LOSS]: 0.48 | [TRAIN ACC]: 77.4% | [VAL LOSS]: 1.60 | [VAL ACC]: 75.4%\n",
            "[EPOCH]: 16 | [LR]: 0.001 | [TRAIN LOSS]: 0.47 | [TRAIN ACC]: 77.7% | [VAL LOSS]: 1.60 | [VAL ACC]: 75.3%\n",
            "[EPOCH]: 17 | [LR]: 0.001 | [TRAIN LOSS]: 0.45 | [TRAIN ACC]: 78.3% | [VAL LOSS]: 1.57 | [VAL ACC]: 76.3%\n",
            "[EPOCH]: 18 | [LR]: 0.001 | [TRAIN LOSS]: 0.44 | [TRAIN ACC]: 79.3% | [VAL LOSS]: 1.67 | [VAL ACC]: 75.6%\n",
            "[EPOCH]: 19 | [LR]: 0.001 | [TRAIN LOSS]: 0.43 | [TRAIN ACC]: 79.2% | [VAL LOSS]: 1.65 | [VAL ACC]: 76.2%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0QLZfEyznVpT",
        "colab_type": "code",
        "outputId": "dba19425-2ab7-49a9-844d-25015a7db71f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot performance\n",
        "trainer.plot_performance()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2gAAAE+CAYAAAD4XjP+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9b5a53bef0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "BWGzMSaBnYMb",
        "colab_type": "code",
        "outputId": "f26dab13-c556-47ed-c3b6-e167979505ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Test performance\n",
        "trainer.run_test_loop()\n",
        "print(\"Test loss: {0:.2f}\".format(trainer.train_state['test_loss']))\n",
        "print(\"Test Accuracy: {0:.1f}%\".format(trainer.train_state['test_acc']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.65\n",
            "Test Accuracy: 73.4%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5672VEginYnY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save all results\n",
        "trainer.save_train_state()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HN1g2vP3nad_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ]
    },
    {
      "metadata": {
        "id": "Myr8QQjKnZ7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Inference(object):\n",
        "    def __init__(self, model, vectorizer):\n",
        "        self.model = model\n",
        "        self.vectorizer = vectorizer\n",
        "  \n",
        "    def predict_nationality(self, surname):\n",
        "        # Forward pass\n",
        "        vectorized_surname = torch.tensor(self.vectorizer.vectorize(surname)).unsqueeze(0)\n",
        "        self.model.eval()\n",
        "        y_pred = self.model(vectorized_surname, apply_softmax=True)\n",
        "\n",
        "        # Top nationality\n",
        "        y_prob, indices = y_pred.max(dim=1)\n",
        "        index = indices.item()\n",
        "\n",
        "        # Predicted nationality\n",
        "        nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
        "        probability = y_prob.item()\n",
        "        return {'nationality': nationality, 'probability': probability}\n",
        "  \n",
        "    def predict_top_k(self, surname, k):\n",
        "        # Forward pass\n",
        "        vectorized_surname = torch.tensor(self.vectorizer.vectorize(surname)).unsqueeze(0)\n",
        "        self.model.eval()\n",
        "        y_pred = self.model(vectorized_surname, apply_softmax=True)\n",
        "\n",
        "        # Top k nationalities\n",
        "        y_prob, indices = torch.topk(y_pred, k=k)\n",
        "        probabilities = y_prob.detach().numpy()[0]\n",
        "        indices = indices.detach().numpy()[0]\n",
        "\n",
        "        # Results\n",
        "        results = []\n",
        "        for probability, index in zip(probabilities, indices):\n",
        "            nationality = self.vectorizer.nationality_vocab.lookup_index(index)\n",
        "            results.append({'nationality': nationality, 'probability': probability})\n",
        "\n",
        "        return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vV2SBrXpdllN",
        "colab_type": "code",
        "outputId": "6837bccd-ecc9-438c-8d97-fd251f3e49f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "print (\"Reloading!\")\n",
        "dataset = SurnameDataset.load_dataset_and_load_vectorizer(\n",
        "    args.split_data_file, args.vectorizer_file)\n",
        "vectorizer = dataset.vectorizer\n",
        "model = SurnameModel(num_input_channels=len(vectorizer.surname_vocab),\n",
        "                     num_channels=args.num_filters,\n",
        "                     num_classes=len(vectorizer.nationality_vocab),\n",
        "                     dropout_p=args.dropout_p)\n",
        "model.load_state_dict(torch.load(args.model_state_file))\n",
        "model = model.to(args.device)\n",
        "print (model.named_modules)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reloading!\n",
            "<bound method Module.named_modules of SurnameModel(\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(28, 100, kernel_size=(2,), stride=(1,))\n",
            "    (1): Conv1d(28, 100, kernel_size=(3,), stride=(1,))\n",
            "    (2): Conv1d(28, 100, kernel_size=(4,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1)\n",
            "  (fc1): Linear(in_features=300, out_features=18, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TRc5KCZinaBh",
        "colab_type": "code",
        "outputId": "8e1ec59d-b159-42ed-d167-c1dddd67b956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "inference = Inference(model=model, vectorizer=vectorizer)\n",
        "surname = input(\"Enter a surname to classify: \")\n",
        "prediction = inference.predict_nationality(preprocess_text(surname))\n",
        "print(\"{} -> {} (p={:0.2f})\".format(surname, prediction['nationality'], \n",
        "                                    prediction['probability']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a surname to classify: Goku\n",
            "Goku -> Japanese (p=0.98)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P5slsQKwnZ_H",
        "colab_type": "code",
        "outputId": "3e60f098-03a8-465d-8a94-6e6377f356b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Top-k inference\n",
        "top_k = inference.predict_top_k(preprocess_text(surname), k=3)\n",
        "for result in top_k:\n",
        "    print (\"{} -> {} (p={:0.2f})\".format(surname, result['nationality'], \n",
        "                                         result['probability']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Goku -> Japanese (p=0.98)\n",
            "Goku -> Russian (p=0.01)\n",
            "Goku -> Czech (p=0.00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HQSsKNRSxjRB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Batch normalization"
      ]
    },
    {
      "metadata": {
        "id": "r3EamVazx2hx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Even though we standardized our inputs to have zero mean and unit variance to aid with convergence, our inputs change during training as they go through the different layers and nonlinearities. This is known as internal covariate shirt and it slows down training and requires us to use smaller learning rates. The solution is [batch normalization](https://arxiv.org/abs/1502.03167) (batchnorm) which makes normalization a part of the model's architecture. This allows us to use much higher learning rates and get better performance, faster.\n",
        "\n",
        "$ BN = \\frac{a - \\mu_{x}}{\\sqrt{\\sigma^2_{x} + \\epsilon}}  * \\gamma + \\beta $\n",
        "\n",
        "where:\n",
        "* $a$ = activation | $\\in \\mathbb{R}^{NXH}$ ($N$ is the number of samples, $H$ is the hidden dim)\n",
        "* $ \\mu_{x}$ = mean of each hidden | $\\in \\mathbb{R}^{1XH}$\n",
        "* $\\sigma^2_{x}$ = variance of each hidden | $\\in \\mathbb{R}^{1XH}$\n",
        "* $epsilon$ = noise\n",
        "* $\\gamma$ = scale parameter (learned parameter)\n",
        "* $\\beta$ = shift parameter (learned parameter)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9koMITOdzfZB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "But what does it mean for our activations to have zero mean and unit variance before the nonlinearity operation. It doesn't mean that the entire activation matrix has this property but instead batchnorm is applied on the hidden (num_channels in our case) dimension. So each hidden's mean and variance is calculated using all samples across the batch. Also, batchnorm uses the calcualted mean and variance of the activations in the batch during training. However, during test, the sample size could be skewed so the model uses the saved population mean and variance from training. PyTorch's [BatchNorm](https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm1d) class takes care of all of this for us automatically.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/batchnorm.png\" width=400>"
      ]
    },
    {
      "metadata": {
        "id": "feUe-KGixjs-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model with batch normalization\n",
        "class SurnameModel(nn.Module):\n",
        "    def __init__(self, num_input_channels, num_channels, num_classes, dropout_p):\n",
        "        super(SurnameModel, self).__init__()\n",
        "        \n",
        "        # Conv weights\n",
        "        self.conv = nn.ModuleList([nn.Conv1d(num_input_channels, num_channels, \n",
        "                                             kernel_size=f) for f in [2,3,4]])\n",
        "        self.conv_bn = nn.ModuleList([nn.BatchNorm1d(num_channels) # define batchnorms\n",
        "                                      for i in range(3)])\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "     \n",
        "        # FC weights\n",
        "        self.fc1 = nn.Linear(num_channels*3, num_classes)\n",
        "\n",
        "    def forward(self, x_in, channel_first=False, apply_softmax=False):\n",
        "        \n",
        "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2)\n",
        "            \n",
        "        # Conv outputs\n",
        "        z1 = self.conv_bn[0](self.conv[0](x_in)) # apply batch norm   \n",
        "        z1 = F.max_pool1d(z1, z1.size(2)).squeeze(2)\n",
        "        z2 = self.conv_bn[0](self.conv[1](x_in))  # apply batch norm   \n",
        "        z2 = F.max_pool1d(z2, z2.size(2)).squeeze(2)\n",
        "        z3 = self.conv_bn[0](self.conv[2](x_in))  # apply batch norm   \n",
        "        z3 = F.max_pool1d(z3, z3.size(2)).squeeze(2)\n",
        "        \n",
        "        # Concat conv outputs\n",
        "        z = torch.cat([z1, z2, z3], 1)\n",
        "        z = self.dropout(z)\n",
        "\n",
        "        # FC layer\n",
        "        y_pred = self.fc1(z)\n",
        "        \n",
        "        if apply_softmax:\n",
        "            y_pred = F.softmax(y_pred, dim=1)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tBXzxtiaxmXi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can train this model with batch normalization and you'll notice that the validation results improve by ~2-5%."
      ]
    },
    {
      "metadata": {
        "id": "w6WRq-O3d1ba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TODO"
      ]
    },
    {
      "metadata": {
        "id": "oEcbaRswd1d0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* image classification example\n",
        "* segmentation\n",
        "* deep CNN architectures\n",
        "* small 3X3 filters\n",
        "* details on padding and stride (control receptive field, make every pixel the center of the filter, etc.)\n",
        "* network-in-network (1x1 conv)\n",
        "* residual connections / residual block\n",
        "* interpretability (which n-grams fire)"
      ]
    }
  ]
}